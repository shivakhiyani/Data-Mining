# -*- coding: utf-8 -*-
"""spambase Q3HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16qo57JBWNKu69yx78zI0oW0QQ3eEauIL
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import fashion_mnist,mnist
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model



from google.colab import files 
  
  
uploaded = files.upload()

data= pd.read_csv("spambase.data", header=None)
data.rename(columns={57:'is_spam'}, inplace=True)


data_train, data_test = train_test_split(data, train_size=0.7)
# ham_train, ham_test = train_test_split(ham, train_size=0.6)
x_train = data_train.drop('is_spam', 1)
x_train = np.asarray(x_train)
x_test = data_test.drop('is_spam', 1)
x_test = np.asarray(x_test)


y_train = data_train.pop('is_spam')
y_test = data_test.pop('is_spam')

print(x_train.shape)
latent_dim=5

class Autoencoder(Model):
  def __init__(self, latent_dim):
    super(Autoencoder,self).__init__()
    self.latent_dim=latent_dim
    self.encoder = tf.keras.Sequential([
      layers.Dense(latent_dim,activation='relu'),
    ])
    self.decoder=tf.keras.Sequential([
      layers.Dense(57,activation='sigmoid')

    ])
  def call(self,x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Autoencoder(latent_dim)
autoencoder.compile(optimizer='adam',loss=losses.MeanSquaredError())
autoencoder.fit(x_train,x_train,
                epochs=5,
                shuffle=True,
                steps_per_epoch=50,
                validation_data=(x_test,x_test),
                validation_steps=2

                )
encoded_train = autoencoder.encoder(x_train).numpy()

encoded_t = autoencoder.encoder(x_test).numpy()
decoded_t = autoencoder.decoder(encoded_t).numpy()

# print(encoded_t)
# print(y_test)

#  from sklearn.linear_model import LogisticRegression
#  logistic_model = LogisticRegression(penalty="l2",C=2, multi_class="ovr")
#  logistic_model.fit(x_train,y_train)
#  print(logistic_model.score(x_train,y_train))
#  print(logistic_model.coef_)

# y_test_predict = logistic_model.predict(x_test)
# print(logistic_model.score(x_test,y_test))
# print(classification_report(y_test,y_test_predict))

# Y_test_predict = logistic_model.predict(encoded_t)
# print(logistic_model.score(encoded_t,y_test))
# print(classification_report(encoded_t,Y_test_predict))

from sklearn.metrics import pairwise#_distances
#dist_out = 1-pairwise_distances(vector2,vector1, metric="cosine")
similarity_matrix1= pairwise.cosine_similarity(encoded_train, encoded_t)
similarity_matrix2= pairwise.cosine_similarity(x_train, x_test)

print(similarity_matrix1[100])
print(similarity_matrix2[100])

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5).fit(encoded_train, y_train)
knn.score(encoded_t,y_test)